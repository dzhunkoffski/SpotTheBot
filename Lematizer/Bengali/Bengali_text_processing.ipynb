{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bengali_text_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uZF45UCgPKx5"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up environment (donwload and import libs)"
      ],
      "metadata": {
        "id": "uZF45UCgPKx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dALtw7m-O2st",
        "outputId": "bd77e2ae-4b3c-4ed8-e3ee-54d3f988de35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-19 11:34:15--  http://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://setup.johnsnowlabs.com/colab.sh [following]\n",
            "--2022-05-19 11:34:15--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-05-19 11:34:16--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1603 (1.6K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-05-19 11:34:16 (18.8 MB/s) - written to stdout [1603/1603]\n",
            "\n",
            "setup Colab for PySpark 3.0.3 and Spark NLP 3.4.4\n",
            "Installing PySpark 3.0.3 and Spark NLP 3.4.4\n",
            "\u001b[K     |████████████████████████████████| 209.1 MB 55 kB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 34.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.5 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# SPARK-NLP FOR TOKENIZATION, LEMATIZATION, PoS\n",
        "!wget http://setup.johnsnowlabs.com/colab.sh -O - | bash"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install alphabet-detector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ija9-xRBPXsf",
        "outputId": "7fe22592-b4f3-4773-a12c-d9dad3addb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting alphabet-detector\n",
            "  Downloading alphabet-detector-0.0.7.tar.gz (1.6 kB)\n",
            "Building wheels for collected packages: alphabet-detector\n",
            "  Building wheel for alphabet-detector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alphabet-detector: filename=alphabet_detector-0.0.7-py3-none-any.whl size=2446 sha256=cd2052d9652fe88426004cca4917c7f27ed36a3890eb0a8ccb38af14f6aa00fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/8c/ab/4afb1765f2b8450f894a1f06c9aa2b3f8e73f2fb8b55849e17\n",
            "Successfully built alphabet-detector\n",
            "Installing collected packages: alphabet-detector\n",
            "Successfully installed alphabet-detector-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "import sparknlp\n",
        "from sparknlp.pretrained import PretrainedPipeline\n",
        "from alphabet_detector import AlphabetDetector"
      ],
      "metadata": {
        "id": "ugxjJT3LPaPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aczty4_iQkVL",
        "outputId": "ac47de07-2847-4dc8-c414-cfa05321631a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 3.4.4\n",
            "Apache Spark version: 3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()\n",
        "print(\"Spark NLP version: {}\".format(sparknlp.version()))\n",
        "print(\"Apache Spark version: {}\".format(spark.version))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwT6JEJ_QnFs",
        "outputId": "d0367ab2-d717-46d9-f0fc-d81f6ebc7b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version: 3.4.4\n",
            "Apache Spark version: 3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"text\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "tokenizer = Tokenizer()\\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "\n",
        "lemmatizer = LemmatizerModel.pretrained(\"lemma\", \"bn\") \\\n",
        "        .setInputCols([\"token\"]) \\\n",
        "        .setOutputCol(\"lemma\")\n",
        "\n",
        "stop_words = StopWordsCleaner.pretrained('stopwords_bn', 'bn')\\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"cleanTokens\") \\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "pos = PerceptronModel.pretrained(\"pos_msri\", \"bn\") \\\n",
        "  .setInputCols([\"document\", \"token\"]) \\\n",
        "  .setOutputCol(\"pos\")\n",
        "\n",
        "nlp_pipeline = Pipeline(stages=[document_assembler, tokenizer, lemmatizer, stop_words, pos])\n",
        "light_pipeline = LightPipeline(nlp_pipeline.fit(spark.createDataFrame([[\"\"]]).toDF(\"text\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlitOQemTQ7Q",
        "outputId": "f2c0a021-bb31-41e3-f06a-212346c8830d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma download started this may take some time.\n",
            "Approximate size to download 90.6 KB\n",
            "[OK!]\n",
            "stopwords_bn download started this may take some time.\n",
            "Approximate size to download 1.9 KB\n",
            "[OK!]\n",
            "pos_msri download started this may take some time.\n",
            "Approximate size to download 806.5 KB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text processing (explanation)"
      ],
      "metadata": {
        "id": "RHamDDSJSaty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main aim of preprocessing is clearing text from:\n",
        "* stop-words\n",
        "* auxiliary part of speech\n",
        "* proper nouns (I am changing them to word \"জিনিস\" - \"object\")\n",
        "* numbers (I am changing them to word \"সংখ্যা\" - \"number\")\n",
        "* punctuation and other symbols"
      ],
      "metadata": {
        "id": "us86MgstShhz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am also changing all pronouns to the word \"জিনিস\" - \"object\". Below listed all part of speeches that model can distinguish and what I'm doing with them in text preprocessing:"
      ],
      "metadata": {
        "id": "kHh3mNvzV-1U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- NN - noun \\\\\n",
        "- SYM - symbol (delete) \\\\\n",
        "- NNP - propper noun (change to \"object\") \\\\\n",
        "- VM - modal verb \\\\\n",
        "- INTF - intesifier (delete) \\\\\n",
        "- JJ - Adjective \\\\\n",
        "- QF - Quantifiers (delete) \\\\\n",
        "- CC - coordinating conjunction (delete) \\\\\n",
        "- NST - noun \\\\\n",
        "- PSP - adposition (delete) \\\\\n",
        "- DEM - pronoun (change to \"object\") \\\\\n",
        "- PRP - posessive pronoun (change to \"object\") \\\\\n",
        "- NEG - negative (delete) \\\\\n",
        "- WQ - wh-qual (delete) \\\\\n",
        "- RB - adverb \\\\\n",
        "- VAUX - Verb Auxiliary (delete) \\\\\n",
        "- UT (delete) \\\\\n",
        "- XC (delete) \\\\\n",
        "- RP - particle (delete) \\\\\n",
        "- Q0 - ordinal number (change to \"number\") \\\\\n",
        "- QC - cardinal number (change to \"number\") \\\\\n",
        "- BM - (delete) \\\\\n",
        "- NNC - compound noun \\\\\n",
        "- PPR - postposition (delete) \\\\\n",
        "- INJ - delete \\\\\n",
        "- CL - delete \\\\\n",
        "- UNK - delete \\\\"
      ],
      "metadata": {
        "id": "sckhsiQ4WxMh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stop words i'm clearing form text are listed here \\\\\n",
        "(https://github.com/stopwords-iso/stopwords-bn/blob/master/stopwords-bn.txt)"
      ],
      "metadata": {
        "id": "wd1uioXKXmMw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the words of other parts of speech, I highlight the initial form. \n",
        "As i understood from wikipedia, some part of speech in bengali has different forms of word (like nominative, objective, genetive, locative noun inflections). As a result, I get a text containing the initial forms of words and cleaned during preprocessing. Here is an example of how it should work for english language:"
      ],
      "metadata": {
        "id": "VG3hb2mFYG-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In:** She jumped into the river and breathed heavily. \\\\\n",
        "**Out:** Object jump river breath heavily "
      ],
      "metadata": {
        "id": "gN2ZtWVVZWP6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Actual code for text processer and several examples:"
      ],
      "metadata": {
        "id": "3eEkP4RUacm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/stopwords-iso/stopwords-bn/blob/master/stopwords-bn.txt "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhAxLotQaj_e",
        "outputId": "df782e77-7aa3-4399-920c-232b469d03a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-19 11:36:42--  https://github.com/stopwords-iso/stopwords-bn/blob/master/stopwords-bn.txt\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘stopwords-bn.txt’\n",
            "\n",
            "stopwords-bn.txt        [ <=>                ] 218.26K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-05-19 11:36:42 (2.10 MB/s) - ‘stopwords-bn.txt’ saved [223502]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('stopwords-bn.txt', 'r', encoding='utf-8') as stopfile:\n",
        "  text = stopfile.read()\n",
        "  stopwords = text.split('\\n')\n",
        "print('Web stop_words:', len(stopwords))\n",
        "stop_set = set(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hf3EZ4qbFEv",
        "outputId": "48649952-4373-45e2-d981-be174883f939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Web stop_words: 3014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "banned_types = {'SYM', 'INTF', 'QF', 'CC', 'PSP', 'RDP', 'NEG', 'WQ', 'VAUX', 'UT', 'XC', 'RP', 'BM', 'PPR', 'INJ', 'CL', 'UNK'}\n",
        "pron_types = {'NNP', 'DEM', 'PRP'}\n",
        "number_types = {'QO', 'QC'}\n",
        "forbidden_chars = {'\"','0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0','!', '@', '#', '$', '^', '&', '*', '—','’','‘',']','[','_','·','.%',')',\n",
        "'(','”','“','\\u3000',\"、\",\"。\",\"〈\",\"〉\",\"《\"}"
      ],
      "metadata": {
        "id": "zYJntxGqb5L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_bn_text(text_in, debug=False):\n",
        "  ad = AlphabetDetector()\n",
        "  results = light_pipeline.fullAnnotate([text_in])\n",
        "  text_out = \"\"\n",
        "\n",
        "  for i in range(len(results[0]['lemma'])):\n",
        "    token = results[0]['token'][i].result\n",
        "    lemm = results[0]['lemma'][i].result\n",
        "    pt = results[0]['pos'][i].result\n",
        "\n",
        "    if not \"LATIN\" in ad.detect_alphabet(token) and token not in stop_set and lemm not in stop_set and pt not in banned_types and len(set(token).intersection(forbidden_chars)) == 0:\n",
        "      if pt in pron_types:\n",
        "        text_out += 'জিনিস '\n",
        "        if debug:\n",
        "          print(token, \"-->\", \"জিনিস\", pt)\n",
        "      elif pt in number_types:\n",
        "        text_out += 'সংখ্যা '\n",
        "        if debug:\n",
        "          print(token, \"-->\", \"সংখ্যা\", pt)\n",
        "      else:\n",
        "        lemm = re.sub(r'[^\\w\\s]', '', lemm)\n",
        "        text_out += lemm\n",
        "        text_out += ' '\n",
        "        if debug:\n",
        "          print(token, \"-->\", lemm, pt)\n",
        "    else:\n",
        "      if debug:\n",
        "        print(token, \"-->\", \"[deleted]\", pt)\n",
        "  return text_out"
      ],
      "metadata": {
        "id": "HFr49lfpcEW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run cells below for testing"
      ],
      "metadata": {
        "id": "Ypt-28Mvevuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List of sentences to test preprocesser. You can put sentence to test in this list\n",
        "texts = [\n",
        "  'ধারা ১: সমস্ত মানুষ স্বাধীনভাবে সমান মর্যাদা এবং অধিকার নিয়ে জন্মগ্রহণ করে। তাঁদের বিবেক এবং বুদ্ধি আছে; সুতরাং সকলেরই একে অপরের প্রতি ভ্রাতৃত্বসুলভ মনোভাব নিয়ে আচরণ করা উচিৎ।',\n",
        "  'একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও',\n",
        "  'তিনি জানালা খোলা এবং দেখেছি একটি গাছ পাখি.'\n",
        "]"
      ],
      "metadata": {
        "id": "j1WJXZoybhzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "for text in texts:\n",
        "  print(\"Test\", i)\n",
        "  i += 1\n",
        "\n",
        "  print('\\033[1m' + \"In:\" +  '\\033[0m', text)\n",
        "  print('\\033[1m' + \"Out:\" +  '\\033[0m', clean_bn_text(text, True)) # Can set False instead of True to get rid off \"A --> B\" debug output \n",
        "  print(\"==========================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDEJ-S-4epCa",
        "outputId": "a0334a2d-e335-47b3-d180-39c361274fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 1\n",
            "\u001b[1mIn:\u001b[0m ধারা ১: সমস্ত মানুষ স্বাধীনভাবে সমান মর্যাদা এবং অধিকার নিয়ে জন্মগ্রহণ করে। তাঁদের বিবেক এবং বুদ্ধি আছে; সুতরাং সকলেরই একে অপরের প্রতি ভ্রাতৃত্বসুলভ মনোভাব নিয়ে আচরণ করা উচিৎ।\n",
            "ধারা --> ধর NN\n",
            "১ --> সংখ্যা QC\n",
            ": --> [deleted] SYM\n",
            "সমস্ত --> সমসত JJ\n",
            "মানুষ --> মনষ NN\n",
            "স্বাধীনভাবে --> সবধনভব RB\n",
            "সমান --> সমন JJ\n",
            "মর্যাদা --> মরযদ NN\n",
            "এবং --> [deleted] CC\n",
            "অধিকার --> অধকর NN\n",
            "নিয়ে --> নয JJ\n",
            "জন্মগ্রহণ --> জনমগরহণ NN\n",
            "করে। --> কর NN\n",
            "তাঁদের --> জিনিস PRP\n",
            "বিবেক --> ববক JJ\n",
            "এবং --> [deleted] CC\n",
            "বুদ্ধি --> বদধ NN\n",
            "আছে --> আছ VM\n",
            "; --> [deleted] SYM\n",
            "সুতরাং --> সতর JJ\n",
            "সকলেরই --> সকলরই NN\n",
            "একে --> সংখ্যা QC\n",
            "অপরের --> অপরর NN\n",
            "প্রতি --> [deleted] PSP\n",
            "ভ্রাতৃত্বসুলভ --> ভরততবসলভ NN\n",
            "মনোভাব --> মনভব NN\n",
            "নিয়ে --> নয JJ\n",
            "আচরণ --> আচরণ NN\n",
            "করা --> কর VM\n",
            "উচিৎ। --> [deleted] VAUX\n",
            "\u001b[1mOut:\u001b[0m ধর সংখ্যা সমসত মনষ সবধনভব সমন মরযদ অধকর নয জনমগরহণ কর জিনিস ববক বদধ আছ সতর সকলরই সংখ্যা অপরর ভরততবসলভ মনভব নয আচরণ কর \n",
            "==========================================================\n",
            "Test 2\n",
            "\u001b[1mIn:\u001b[0m একদিন প্রাতে বৈদ্যনাথের মার্বলমণ্ডিত দালানে একটি স্থূলোদর সন্ন্যাসী দুইসের মোহনভোগ এবং দেড়সের দুগ্ধ সেবায় নিযুক্ত আছে বৈদ্যনাথ গায়ে একখানি চাদর দিয়া জোড়করে একান্ত বিনীতভাবে ভূতলে বসিয়া ভক্তিভরে পবিত্র ভোজনব্যাপার নিরীক্ষণ করিতেছিলেন এমন সময় কোনোমতে দ্বারীদের দৃষ্টি এড়াইয়া জীর্ণদেহ বালক সহিত একটি অতি শীর্ণকায়া রমণী গৃহে প্রবেশ করিয়া ক্ষীণস্বরে কহিল বাবু দুটি খেতে দাও\n",
            "একদিন --> একদন NN\n",
            "প্রাতে --> পরত NN\n",
            "বৈদ্যনাথের --> বদযনথ NN\n",
            "মার্বলমণ্ডিত --> মরবলমণডত NN\n",
            "দালানে --> দলন NN\n",
            "একটি --> সংখ্যা QC\n",
            "স্থূলোদর --> সথলউদর JJ\n",
            "সন্ন্যাসী --> সননযস NN\n",
            "দুইসের --> দইসর NN\n",
            "মোহনভোগ --> মহনভগ NN\n",
            "এবং --> [deleted] CC\n",
            "দেড়সের --> দডসর NN\n",
            "দুগ্ধ --> দগধ NN\n",
            "সেবায় --> সব NN\n",
            "নিযুক্ত --> নযকত JJ\n",
            "আছে --> আছ VM\n",
            "বৈদ্যনাথ --> [deleted] XC\n",
            "গায়ে --> গ NN\n",
            "একখানি --> সংখ্যা QC\n",
            "চাদর --> চদর NN\n",
            "দিয়া --> [deleted] PSP\n",
            "জোড়করে --> জডকর NN\n",
            "একান্ত --> একনত RB\n",
            "বিনীতভাবে --> বনতভব RB\n",
            "ভূতলে --> ভতল NN\n",
            "বসিয়া --> বস VM\n",
            "ভক্তিভরে --> [deleted] VAUX\n",
            "পবিত্র --> পবতর JJ\n",
            "ভোজনব্যাপার --> ভজনবযপর NN\n",
            "নিরীক্ষণ --> নরকষণ NN\n",
            "করিতেছিলেন --> কর VM\n",
            "এমন --> জিনিস DEM\n",
            "সময় --> সময় NN\n",
            "কোনোমতে --> কনমত NN\n",
            "দ্বারীদের --> দবর NN\n",
            "দৃষ্টি --> দষট NN\n",
            "এড়াইয়া --> জিনিস PRP\n",
            "জীর্ণদেহ --> জরণদহ NN\n",
            "বালক --> বলক NN\n",
            "সহিত --> সহত NN\n",
            "একটি --> সংখ্যা QC\n",
            "অতি --> [deleted] INTF\n",
            "শীর্ণকায়া --> শরণকয় JJ\n",
            "রমণী --> রমণ NN\n",
            "গৃহে --> গহ NN\n",
            "প্রবেশ --> পরবশ NN\n",
            "করিয়া --> বশবস VM\n",
            "ক্ষীণস্বরে --> কষণসবর NN\n",
            "কহিল --> কহ JJ\n",
            "বাবু --> বব NN\n",
            "দুটি --> সংখ্যা QC\n",
            "খেতে --> খওয় NN\n",
            "দাও --> [deleted] VAUX\n",
            "\u001b[1mOut:\u001b[0m একদন পরত বদযনথ মরবলমণডত দলন সংখ্যা সথলউদর সননযস দইসর মহনভগ দডসর দগধ সব নযকত আছ গ সংখ্যা চদর জডকর একনত বনতভব ভতল বস পবতর ভজনবযপর নরকষণ কর জিনিস সময় কনমত দবর দষট জিনিস জরণদহ বলক সহত সংখ্যা শরণকয় রমণ গহ পরবশ বশবস কষণসবর কহ বব সংখ্যা খওয় \n",
            "==========================================================\n",
            "Test 3\n",
            "\u001b[1mIn:\u001b[0m তিনি জানালা খোলা এবং দেখেছি একটি গাছ পাখি.\n",
            "তিনি --> জিনিস PRP\n",
            "জানালা --> জনল NN\n",
            "খোলা --> খল VM\n",
            "এবং --> [deleted] CC\n",
            "দেখেছি --> সংখ্যা QC\n",
            "একটি --> সংখ্যা QC\n",
            "গাছ --> গছ NN\n",
            "পাখি --> পখ NN\n",
            ". --> [deleted] SYM\n",
            "\u001b[1mOut:\u001b[0m জিনিস জনল খল সংখ্যা সংখ্যা গছ পখ \n",
            "==========================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HBZR4SDkGyTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}